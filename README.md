# ğŸ—½ NYC Restaurant Inspection Data Pipeline

This project is a pure Python data engineering pipeline that processes and analyzes New York City restaurant inspection data. The pipeline performs the following major steps:

- **Data Loading**
- **Data Cleaning**
- **Data Validation**
- **Data Transformation / Enrichment**
- **Data Storage to SQL Server**
- **SQL-Based Data Cleaning**
- **Automated Stored Procedure Execution**
- (Upcoming: Scheduling, Visualization, Reporting)

---

## ğŸ—ï¸ Project Architecture

```
nyc_data_project/
â”‚
â”œâ”€â”€ config/                   # Config files
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/                     # Raw CSV input files
â”‚
â”œâ”€â”€ logs/                     # Pipeline logs
â”‚   â””â”€â”€ pipeline.log
â”‚
â”œâ”€â”€ output/                   # Output CSVs (cleaned, transformed)
â”‚   â”œâ”€â”€ DOHMH_New_York_City_Restaurant_Inspection_C.csv
â”‚   â””â”€â”€ DOHMH_New_York_City_Restaurant_Inspection_T.csv
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ data_cleaner.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ data_transformer.py
â”‚   â”œâ”€â”€ data_validator.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ pipeline_runner.py
â”‚   â””â”€â”€ save_data.py
â”‚
â”‚â”€â”€ sql/
â”‚   â”œâ”€â”€ 01_create_raw_table.sql
â”‚   â”œâ”€â”€ 02_create_clean_table.sql
â”‚   â”œâ”€â”€ 03_cleaning_procedure.sql
â”‚ 
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â””â”€â”€ README.md


```

---

## ğŸ§ª How to Run the Pipeline

1. **Install dependencies**  
```bash
pip install -r requirements.txt
```

2. **Update config.yaml**  
Make sure `csv_path` points to your raw CSV and `output_path` for saving files.

3. **Run the pipeline**  
```bash
python src/pipeline_runner.py
```

4. **(Optional)**: View cleaned data  
```bash
python view_cleaned_data.py
```

---

## âœ… Completed Modules

- [x] Data Loader
- [x] Data Cleaner
- [x] Data Validator
- [x] Data Transformer
- [x] Logging System (auto truncates on each run)
- [x] SQL Server Integration
- [x] Stored Procedure Execution from Python
- [x] Git + GitHub setup

---

## ğŸ”œ Upcoming

- Data Visualization Dashboard
- Scheduled Automation with Airflow or Cron
- Unit Tests

---

## ğŸ“’ Notes

- All logs are saved in logs/pipeline.log and refreshed each time the pipeline is run.
- The database cleaning logic lives inside the SQL Server stored procedure

---

## ğŸ“Œ Author

**Sree Madhuchandra Gamidi**  
GitHub: [@Madhugamidi14](https://github.com/Madhugamidi14)
